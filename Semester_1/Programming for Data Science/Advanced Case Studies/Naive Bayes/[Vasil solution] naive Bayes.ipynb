{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes classifier practice\n",
    "\n",
    "## (predict if a tweet is about the Mandrill app or not)\n",
    "\n",
    "All our data is in the naive_bayes_data folder. Let's load up the training examples into two lists of tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "app_tweets   = open(\"naive_bayes_data/training_tweets_app.txt\", encoding='utf-8').read().splitlines()\n",
    "other_tweets = open(\"naive_bayes_data/training_tweets_other.txt\", encoding='utf-8').read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check if our tweets loaded up successfully.\n",
    "\n",
    "Feel free to explore the data set by changing the index that we're looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿[blog] Using Nullmailer and Mandrill for your Ubuntu Linux server outboud mail:  http://bit.ly/ZjHOk7  #plone\n"
     ]
    }
   ],
   "source": [
    "print(app_tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿¿En donde esta su remontada Mandrill?\n"
     ]
    }
   ],
   "source": [
    "print(other_tweets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's normalise our tweets, by:\n",
    "* Converting them to lower case\n",
    "* Substituting the punctuation marks dot '.' and colon ':', followed by a space \" \", to just \" \" -- because we don't want to split \"... google.com ...\" into two words, but we want to split \"... Google. Microsoft ...\"\n",
    "* Substituting the punctiation marks \",\", \"?\", \"!\", \";\" to \" \"\n",
    "\n",
    "After this normalisation, we can treat our tweets as sequences of lowercase words separated by spaces \" \"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalise_tweet(tweet):\n",
    "    tweet_lowercase = tweet.lower()\n",
    "    tweet_no_dot = str.replace(tweet_lowercase,\". \", \" \")\n",
    "    tweet_no_colon = str.replace(tweet_no_dot, \": \", \" \")\n",
    "    tweet_no_comma = str.replace(tweet_no_colon, \",\", \" \")\n",
    "    tweet_no_question = str.replace(tweet_no_comma, \"?\", \" \")\n",
    "    tweet_no_exclamation = str.replace(tweet_no_question, \"!\", \" \")\n",
    "    tweet_no_semicolon = str.replace(tweet_no_exclamation, \";\", \" \")\n",
    "    return tweet_no_semicolon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_tweets_normalised   = [normalise_tweet(tweet) for tweet in app_tweets]\n",
    "other_tweets_normalised = [normalise_tweet(tweet) for tweet in other_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's check that our code works on a tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿[blog] Using Nullmailer and Mandrill for your Ubuntu Linux server outboud mail:  http://bit.ly/ZjHOk7  #plone\n",
      "﻿[blog] using nullmailer and mandrill for your ubuntu linux server outboud mail  http://bit.ly/zjhok7  #plone\n"
     ]
    }
   ],
   "source": [
    "print(app_tweets[0])\n",
    "print(app_tweets_normalised[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's split our tweets into the so-called bags of words\n",
    "\n",
    "To do that, we split each tweet by cutting at the space \" \" characters -- and remove duplicated words so that we get each word in a tween just once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_bags_of_words   = [set(tweet.split()) for tweet in app_tweets_normalised]\n",
    "other_bags_of_words = [set(tweet.split()) for tweet in other_tweets_normalised]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'server', '\\ufeff[blog]', 'nullmailer', 'your', 'outboud', 'using', 'mandrill', '#plone', 'linux', 'ubuntu', 'and', 'http://bit.ly/zjhok7', 'mail', 'for'}\n",
      "{'remontada', 'mandrill', 'esta', 'donde', 'su', '\\ufeff¿en'}\n"
     ]
    }
   ],
   "source": [
    "print(app_bags_of_words[0])\n",
    "print(other_bags_of_words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, the pre-processing step is done. Now we have to build the actual naive Bayes model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count how many app/other tweets does every word appear in\n",
    "\n",
    "To do this, we'll use a dictionary with key:word -> value:(# app tweets containing word, # other tweets containing word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_tweet_counts = {}\n",
    "for bag in app_bags_of_words:\n",
    "    for word in bag:\n",
    "        if len(word) > 3:\n",
    "            if word in word_to_tweet_counts:\n",
    "                (app_count, other_count) = word_to_tweet_counts[word]\n",
    "                app_count += 1\n",
    "                word_to_tweet_counts[word] = (app_count,other_count)\n",
    "            else:\n",
    "                word_to_tweet_counts[word] = (1,0) # we have only seen the word in an app tweet\n",
    "for bag in other_bags_of_words:\n",
    "    for word in bag:\n",
    "        if len(word) > 3:\n",
    "            if word in word_to_tweet_counts:\n",
    "                (app_count, other_count) = word_to_tweet_counts[word]\n",
    "                other_count += 1\n",
    "                word_to_tweet_counts[word] = (app_count,other_count)\n",
    "            else:\n",
    "                word_to_tweet_counts[word] = (0,1) # we have only seen the word in an other tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the dictionary is populating well by printing a common word, such as \"mandrill\".\n",
    "\n",
    "Feel free to print other words to check the result, such as \"email\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 89)\n"
     ]
    }
   ],
   "source": [
    "print(word_to_tweet_counts[\"mandrill\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 0)\n"
     ]
    }
   ],
   "source": [
    "print(word_to_tweet_counts[\"email\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in our Bayes model, instead of counts we need to be keeping probabilities that the word would appear in an app/other tweet.\n",
    "\n",
    "P(word|app) = (# word's appearances in an app tweet)/(# app tweets)\n",
    "\n",
    "P(word|other) = (# word's appearances in an other tweet)/(# other tweets)\n",
    "\n",
    "Take care when dividing: is 4/5=0, or is 4/5=0.8?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">In the book they are calculating the probabilities based on the total number of unique words in each dataset, and here they are calculated based on the total number of bags in each dataset. I have fixed this ...\n",
    "</span>\n",
    "\n",
    "<span style=\"color:red\"> Another problem in the cell below is that it doesn't account for the additive smooting ... so I added it\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "num_apps = 0.0\n",
    "num_others = 0.0\n",
    "\n",
    "for word in word_to_tweet_counts:\n",
    "    (app_count,other_count) = word_to_tweet_counts[word]\n",
    "    app_count += app_count + 1.0 \n",
    "    other_count += other_count + 1.0\n",
    "    if app_count > 0.0 : num_apps += app_count\n",
    "    if other_count > 0.0 : num_others += other_count\n",
    "    word_to_tweet_counts[word] = (app_count,other_count)\n",
    "\n",
    "word_to_tweet_probs = {}\n",
    "for word in word_to_tweet_counts:\n",
    "    (app_count,other_count) = word_to_tweet_counts[word]\n",
    "    if app_count != 0 and other_count != 0:\n",
    "        (app_prob,other_prob) = (math.log(app_count/num_apps), math.log(other_count/num_others))\n",
    "    elif app_count == 0:\n",
    "        (app_prob,other_prob) = (math.log(1.0/num_apps), math.log(other_count/num_others))\n",
    "    else:\n",
    "        (app_prob,other_prob) = (math.log(app_count/num_apps),  math.log(1.0/num_others))\n",
    "    word_to_tweet_probs[word] = (app_prob, other_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the probabilities are fine for common words, such as \"and\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App tweets:  4676.0\n",
      "Other tweets:  3960.0\n",
      "Counts for the word:  (3.0, 1.0)\n",
      "Probabilities for the word:  (-7.35158603392385, -8.283999304248526)\n"
     ]
    }
   ],
   "source": [
    "print(\"App tweets: \", num_apps)\n",
    "print(\"Other tweets: \", num_others)\n",
    "print(\"Counts for the word: \", word_to_tweet_counts[\"photo\"])\n",
    "print(\"Probabilities for the word: \", word_to_tweet_probs[\"photo\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to classify our test tweets now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us pre-process the test tweets in the same fashion as we did with the training ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tweets = open(\"naive_bayes_data/test_tweets.txt\", encoding='utf-8').read().splitlines()\n",
    "test_tweets_normalised = [normalise_tweet(tweet) for tweet in test_tweets]\n",
    "test_bags_of_words = [set(tweet.split()) for tweet in test_tweets_normalised]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> The problem in the cell below is that it doesn't account for the additive smooting ... so I added it\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for test_bag in test_bags_of_words:\n",
    "    total_app_prob, total_other_prob = 0.0, 0.0\n",
    "    for word in test_bag:\n",
    "        if word in word_to_tweet_probs:\n",
    "            (app_prob, other_prob) = word_to_tweet_probs[word]\n",
    "        else:\n",
    "            app_prob, other_prob = math.log(1.0/num_apps), math.log(1.0/num_others)\n",
    "        total_app_prob += app_prob\n",
    "        total_other_prob += other_prob\n",
    "    if total_app_prob > total_other_prob:\n",
    "        predictions.append(\"APP\")\n",
    "    else:\n",
    "        predictions.append(\"OTHER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check our predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿Just love @mandrillapp transactional email service - http://mandrill.com Sorry @SendGrid and @mailjet #timetomoveon\n",
      "Our prediction is: APP\n",
      "True class is    : APP\n",
      "\n",
      "\n",
      "@rossdeane Mind submitting a request at http://help.mandrill.com with account details if you haven't already? Glad to take a look!\n",
      "Our prediction is: APP\n",
      "True class is    : APP\n",
      "\n",
      "\n",
      "@veroapp Any chance you'll be adding Mandrill support to Vero?\n",
      "Our prediction is: APP\n",
      "True class is    : APP\n",
      "\n",
      "\n",
      "@Elie__ @camj59 jparle de relai SMTP!1 million de mail chez mandrill / mois comparé à 1 million sur lite sendgrid y a pas photo avec mailjet\n",
      "Our prediction is: APP\n",
      "True class is    : APP\n",
      "\n",
      "\n",
      "would like to send emails for welcome, password resets, payment notifications, etc. what should i use? was looking at mailgun/mandrill\n",
      "Our prediction is: APP\n",
      "True class is    : APP\n",
      "\n",
      "\n",
      "From Coworker about using Mandrill:  \"I would entrust email handling to a Pokemon\".\n",
      "Our prediction is: APP\n",
      "True class is    : APP\n",
      "\n",
      "\n",
      "@mandrill Realised I did that about 5 seconds after hitting send!\n",
      "Our prediction is: APP\n",
      "True class is    : APP\n",
      "\n",
      "\n",
      "Holy shit. It’s here. http://www.mandrill.com/ \n",
      "Our prediction is: APP\n",
      "True class is    : APP\n",
      "\n",
      "\n",
      "Our new subscriber profile page: activity timeline, aggregate engagement stats, and Mandrill integratio #BJCBranding http://bit.ly/13waU5c \n",
      "Our prediction is: APP\n",
      "True class is    : APP\n",
      "\n",
      "\n",
      "@mandrillapp increases scalability ( http://bit.ly/14myVuH  ) then decreases pricing ( http://bit.ly/13uJA7s  ) #selfinducedcannibalization\n",
      "Our prediction is: APP\n",
      "True class is    : APP\n",
      "\n",
      "\n",
      "The Beets! RT @MISSMYA: #NameAnAmazingBand MANDRILL!\n",
      "Our prediction is: OTHER\n",
      "True class is    : OTHER\n",
      "\n",
      "\n",
      "RT @LuisSand0val: Fernando Vargas MANDRILL MEXICAN PRIDE MMA\n",
      "Our prediction is: OTHER\n",
      "True class is    : OTHER\n",
      "\n",
      "\n",
      "Photo: oculi-ds: Mandrill by Natalie Manuel http://tmblr.co/ZJqANxhdSWlr \n",
      "Our prediction is: OTHER\n",
      "True class is    : OTHER\n",
      "\n",
      "\n",
      "@mandrill ME NEITHER!!! we can be :sadpanda: together :(\n",
      "Our prediction is: OTHER\n",
      "True class is    : OTHER\n",
      "\n",
      "\n",
      "@mandrill n! / ( k! * ( n! - k! ) ) where n = 5 and k = 4, it has been a long time but I think that is it\n",
      "Our prediction is: OTHER\n",
      "True class is    : OTHER\n",
      "\n",
      "\n",
      "Megaman X - Spark Mandrill Acapella: http://youtu.be/hyx9-kWYjDI  @youtubeさんから\n",
      "Our prediction is: OTHER\n",
      "True class is    : OTHER\n",
      "\n",
      "\n",
      "@AngelusErrare1 Storm Eagle FTW!!!, nomás no dejes que se le acerque Spark Mandrill XD\n",
      "Our prediction is: OTHER\n",
      "True class is    : OTHER\n",
      "\n",
      "\n",
      "Gostei de um vídeo @YouTube http://youtu.be/XzNY7zimtnI?aSpark … Mandrill's Stage on guitar (Mega Man X)\n",
      "Our prediction is: OTHER\n",
      "True class is    : OTHER\n",
      "\n",
      "\n",
      "What is 2-year-old mandrill, JJ, thinking in this pic? http://ow.ly/jFRqf  Re-tweet with your caption.\n",
      "Our prediction is: APP\n",
      "True class is    : OTHER\n",
      "\n",
      "\n",
      "120 years of Moscow Zoo - Mandrill - Поста СССР, #postage #stamp 3347 from Soviet Union in 1984 #philately http://tinyurl.com/cguyvzb \n",
      "Our prediction is: OTHER\n",
      "True class is    : OTHER\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_tweet_answers = open(\"naive_bayes_data/test_tweets_answers.txt\").read().splitlines()\n",
    "\n",
    "for tweet_number, tweet in enumerate(test_tweets):\n",
    "\n",
    "    print (tweet)\n",
    "    print (\"Our prediction is:\", predictions[tweet_number])\n",
    "    print (\"True class is    :\", test_tweet_answers[tweet_number])\n",
    "    print (\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
